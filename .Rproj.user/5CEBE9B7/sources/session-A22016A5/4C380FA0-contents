---
title: "01_Model_Association"
---

# 01.Load Packages and files
```{r}
library(modelr)
library(mice)
library(VIM)
library(DMwR2)
library(rpart)
library(car)
library(splines)
library(gam)
library(caret)

source('02_src/defined_functions.R')
data_MCPD = read.csv('00_Data/data_MCPD.csv')
```

# 02.Cross-Validation
## Results Output
```{r}
Result_total = data.frame(model = c(0),
                          train_RMSE=c(0), train_R2=c(0), train_MAE=c(0),
                          test_RMSE=c(0), test_R2=c(0), test_MAE=c(0))
K = 5
```

## MLR-1
```{r}
set.seed(208)
folds <- createFolds(data_MCPD$dietaryMCPD, k = K)

# Initialize the result data frame
result.train <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))
result.test <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))

for (i in 1:K) {
  fold.test <- data_MCPD[folds[[i]], ]
  fold.train <- data_MCPD[-folds[[i]], ]
  
  # Train model
  model.mlr <- lm(dietaryMCPD~.
                  + DHPMA_a:HBP
                  + DHPMA_a:MARRIAGE, data = fold.train)
  
  # Performance for training set
  trainpred <- predict(model.mlr, newdata = fold.train)
  temp.train <- defaultSummary(data.frame(obs = fold.train$dietaryMCPD, pred = trainpred))
  result.train[i, ] <- c(temp.train["RMSE"], temp.train["Rsquared"], temp.train["MAE"])
  
  # Performance for test set
  testpred <- predict(model.mlr, newdata = fold.test)
  temp.test <- defaultSummary(data.frame(obs = fold.test$dietaryMCPD, pred = testpred))
  result.test[i, ] <- c(temp.test["RMSE"], temp.test["Rsquared"], temp.test["MAE"])
}

# Extract R2, RMSE, and MAE of the test set
R2_MLR1 <- result.test$R2
RMSE_MLR1 <- result.test$RMSE
MAE_MLR1 <- result.test$MAE

Result_total[1, ] <- c(
  'MLR1',
  mean(result.train$RMSE),
  mean(result.train$R2),
  mean(result.train$MAE),
  mean(result.test$RMSE),
  mean(result.test$R2),
  mean(result.test$MAE)
)
```

## GAM model
```{r}
set.seed(208)
folds <- createFolds(data_MCPD$dietaryMCPD, k = K)

# Initialize the result data frame
result.train <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))
result.test <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))

for (i in 1:K) {
  fold.test <- data_MCPD[folds[[i]], ]
  fold.train <- data_MCPD[-folds[[i]], ]
  
  # Train model
  model.gam <- gam(dietaryMCPD~CREATININE+HEIGHT+BMI+age
                             + s(BEANOILintake) + s(PEANUTOIintake) + s(LARDOILintake) 
                             + s(MET) + s(DHPMA_a) + s(totalenergy)
                             + MARRIAGE + SEX + FAMINCOM5w + CVD + SMOKE        
                             + HBP+alcohol+education
                             + DHPMA_a:HBP
                             + DHPMA_a:MARRIAGE, data = fold.train)
  
  # Performance for training set
  trainpred <- predict(model.gam, newdata = fold.train)
  temp.train <- defaultSummary(data.frame(obs = fold.train$dietaryMCPD, pred = trainpred))
  result.train[i, ] <- c(temp.train["RMSE"], temp.train["Rsquared"], temp.train["MAE"])
  
  # Performance for test set
  testpred <- predict(model.gam, newdata = fold.test)
  temp.test <- defaultSummary(data.frame(obs = fold.test$dietaryMCPD, pred = testpred))
  result.test[i, ] <- c(temp.test["RMSE"], temp.test["Rsquared"], temp.test["MAE"])
}

# Extract R2, RMSE, and MAE of the test set
R2_GAM <- result.test$R2
RMSE_GAM <- result.test$RMSE
MAE_GAM <- result.test$MAE

Result_total[2, ] <- c(
  'GAM',
  mean(result.train$RMSE),
  mean(result.train$R2),
  mean(result.train$MAE),
  mean(result.test$RMSE),
  mean(result.test$R2),
  mean(result.test$MAE)
)
```

## SVR model
```{r}
set.seed(208)
folds <- createFolds(data_MCPD$dietaryMCPD, k = K)

# Initialize the result data frame
result.train <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))
result.test <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))

for (i in 1:K) {
  fold.test <- data_MCPD[folds[[i]], ]
  fold.train <- data_MCPD[-folds[[i]], ]
  
  # Train model
  model.svm <- svm(dietaryMCPD ~ ., data = fold.train, 
                   kernel = 'radial', type = 'eps-regression')
  
  # Performance for training set
  trainpred <- predict(model.svm, newdata = fold.train)
  temp.train <- defaultSummary(data.frame(obs = fold.train$dietaryMCPD, pred = trainpred))
  result.train[i, ] <- c(temp.train["RMSE"], temp.train["Rsquared"], temp.train["MAE"])
  
  # Performance for test set
  testpred <- predict(model.svm, newdata = fold.test)
  temp.test <- defaultSummary(data.frame(obs = fold.test$dietaryMCPD, pred = testpred))
  result.test[i, ] <- c(temp.test["RMSE"], temp.test["Rsquared"], temp.test["MAE"])
}

# Extract R2, RMSE, and MAE of the test set
R2_SVR <- result.test$R2
RMSE_SVR <- result.test$RMSE
MAE_SVR <- result.test$MAE

Result_total[3, ] <- c(
  'SVR',
  mean(result.train$RMSE),
  mean(result.train$R2),
  mean(result.train$MAE),
  mean(result.test$RMSE),
  mean(result.test$R2),
  mean(result.test$MAE)
)
```

## RF Model
```{r}
library(caret)
library(randomForest)

set.seed(208)
folds <- createFolds(y = data_MCPD$dietaryMCPD, k = K)

# Initialize the result data frame
result.train <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))
result.test <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))

for (i in 1:K) {
  fold.test <- data_MCPD[folds[[i]], ]
  fold.train <- data_MCPD[-folds[[i]], ]
  
  # Train model
  model.RF <- randomForest(dietaryMCPD ~ ., data = fold.train, importance = TRUE)
  
  # Performance for training set
  trainpred <- predict(model.RF, newdata = fold.train)
  temp.train <- defaultSummary(data.frame(obs = fold.train$dietaryMCPD, pred = trainpred))
  result.train[i, ] <- c(temp.train["RMSE"], temp.train["Rsquared"], temp.train["MAE"])
  
  # Performance for test set
  testpred <- predict(model.RF, newdata = fold.test)
  temp.test <- defaultSummary(data.frame(obs = fold.test$dietaryMCPD, pred = testpred))
  result.test[i, ] <- c(temp.test["RMSE"], temp.test["Rsquared"], temp.test["MAE"])
}

# Extract R2, RMSE, and MAE of the test set
R2_RF <- result.test$R2
RMSE_RF <- result.test$RMSE
MAE_RF <- result.test$MAE

Result_total[4, ] <- c(
  'RF',
  mean(result.train$RMSE),
  mean(result.train$R2),
  mean(result.train$MAE),
  mean(result.test$RMSE),
  mean(result.test$R2),
  mean(result.test$MAE)
)
```

## LGBM
```{r}
library(lightgbm)
set.seed(208)
folds <- createFolds(y = data_MCPD$dietaryMCPD, k = K)

# Initialize the result data frame
result.train <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))
result.test <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))

for (i in 1:K) {
  test <- data_MCPD[folds[[i]], ]
  trains.all <- data_MCPD[-folds[[i]], ]
  
  # Build Validation Sample to avoid overfitting
  train_indices <- sample(rownames(trains.all), size = floor(nrow(trains.all) * 4/5))
  valid_indices <- setdiff(rownames(trains.all), train_indices)
  
  data_train <- trains.all[train_indices, ]
  data_valid <- trains.all[valid_indices, ]
  
  # Convert data format
  data_trainx <- data.matrix(data_train[, -1])  
  data_trainy <- data.matrix(data_train$dietaryMCPD) # The first column is the target variable
  
  data_validx <- data.matrix(data_valid[, -1])
  data_validy <- data.matrix(data_valid$dietaryMCPD)
  
  data_testx <- data.matrix(test[, -1])
  data_testy <- data.matrix(test$dietaryMCPD)
  
  # Create the LightGBM dataset
  dtrain <- lgb.Dataset(data = data_trainx, label = data_trainy)
  dvalid <- lgb.Dataset(data = data_validx, label = data_validy)
  
  # Train Model
  params <- list(
    objective = 'regression_l2',
    metric = 'rmse'
  )
  
  lgb1 <- lgb.train(
    params = params,
    data = dtrain,
    valids = list(valid = dvalid),
    nrounds = 1500,
    early_stopping_rounds = 10
  )
  
  # Performance for training set
  trainpred <- predict(lgb1, data_trainx)
  temp.train <- defaultSummary(data.frame(obs = data_train$dietaryMCPD, pred = trainpred))
  result.train[i, ] <- c(temp.train["RMSE"], temp.train["Rsquared"], temp.train["MAE"])
  
  # Performance for test set
  testpred <- predict(lgb1, data_testx)
  temp.test <- defaultSummary(data.frame(obs = test$dietaryMCPD, pred = testpred))
  result.test[i, ] <- c(temp.test["RMSE"], temp.test["Rsquared"], temp.test["MAE"])
}

R2_LGBM <- result.test$R2
RMSE_LGBM <- result.test$RMSE
MAE_LGBM <- result.test$MAE

Result_total[5, ] <- c(
  'LGBM',
  mean(result.train$RMSE),
  mean(result.train$R2),
  mean(result.train$MAE),
  mean(result.test$RMSE),
  mean(result.test$R2),
  mean(result.test$MAE)
)
```

## XGBoost
```{r}
library(xgboost)
set.seed(208)
folds <- createFolds(y = data_MCPD$dietaryMCPD, k = K)

# Initialize the result data frame
result.train <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))
result.test <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))

for (i in 1:K) {
  test <- data_MCPD[folds[[i]], ]
  trains.all <- data_MCPD[-folds[[i]], ]
  
  # Build Validation Sample to avoid overfitting
  train_indices <- sample(rownames(trains.all), size = floor(nrow(trains.all) * 4/5))
  valid_indices <- setdiff(rownames(trains.all), train_indices)
  
  data_train <- trains.all[train_indices, ]
  data_valid <- trains.all[valid_indices, ]
  data_test <- test
  
  # Prapare Data
  dvfunc <- dummyVars(~., data = data_train[, -1], fullRank = TRUE)
  
  data_trainx <- predict(dvfunc, newdata = data_train[, -1])
  data_trainy <- data_train$dietaryMCPD
  
  data_validx <- predict(dvfunc, newdata = data_valid[, -1])
  data_validy <- data_valid$dietaryMCPD
  
  data_testx <- predict(dvfunc, newdata = data_test[, -1])
  data_testy <- data_test$dietaryMCPD
  
  # Create the XGBoost data matrix
  dtrain <- xgb.DMatrix(data = data_trainx, label = data_trainy)
  dvalid <- xgb.DMatrix(data = data_validx, label = data_validy)
  dtest <- xgb.DMatrix(data = data_testx, label = data_testy)
  watchlist <- list(train = dtrain, valid = dvalid)  # avoid overfitting
  
  # Model Training
  fit_xgb_reg <- xgb.train(
    params = list(
      objective = 'reg:squarederror',
      eval_metric = 'rmse'
    ),
    data = dtrain,
    nrounds = 1500,
    watchlist = watchlist,
    early_stopping_rounds = 10,
    verbose = 0
  )
  
  # Performance for training set
  trainpred <- predict(fit_xgb_reg, newdata = data_trainx)
  temp.train <- defaultSummary(data.frame(obs = data_train$dietaryMCPD, pred = trainpred))
  result.train[i, ] <- c(temp.train["RMSE"], temp.train["Rsquared"], temp.train["MAE"])
  
  # Performance for test set
  testpred <- predict(fit_xgb_reg, newdata = data_testx)
  temp.test <- defaultSummary(data.frame(obs = data_test$dietaryMCPD, pred = testpred))
  result.test[i, ] <- c(temp.test["RMSE"], temp.test["Rsquared"], temp.test["MAE"])
}

R2_XGB <- result.test$R2
RMSE_XGB <- result.test$RMSE
MAE_XGB <- result.test$MAE

Result_total[6, ] <- c(
  'XGB',
  mean(result.train$RMSE),
  mean(result.train$R2),
  mean(result.train$MAE),
  mean(result.test$RMSE),
  mean(result.test$R2),
  mean(result.test$MAE)
)
```


## CatBoost
```{r}
library(catboost)
set.seed(208)
folds <- createFolds(y = data_MCPD$dietaryMCPD, k = K)

# Initialize the result data frame
result.train <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))
result.test <- data.frame(RMSE = numeric(K), R2 = numeric(K), MAE = numeric(K))

for (i in 1:K) {
  fold.test <- data_MCPD[folds[[i]], ]
  fold.train <- data_MCPD[-folds[[i]], ]
  
  # Prepare the CatBoost data pool
  train_pool <- catboost.load_pool(data = fold.train[, -target], 
                                   label = as.matrix(fold.train[, target]),
                                   cat_features = cat_features)	
  test_pool <- catboost.load_pool(data = fold.test[, -target], 
                                  label = as.matrix(fold.test[, target]),
                                  cat_features = cat_features)
  
  # 设置CatBoost模型的参数
  fit_params <- list(
    iterations = 300,
    thread_count = 10,
    loss_function = 'RMSE',
    train_dir = 'train_dir',
    logging_level = 'Silent'
  )
  
  # 训练CatBoost模型
  model.cat <- catboost.train(train_pool, test_pool, fit_params)
  
  # 训练集预测
  trainpred <- catboost.predict(model.cat, train_pool)
  temp.train <- defaultSummary(data.frame(obs = fold.train$dietaryMCPD, pred = trainpred))
  result.train[i, ] <- c(temp.train["RMSE"], temp.train["Rsquared"], temp.train["MAE"])
  
  # 测试集预测
  testpred <- catboost.predict(model.cat, test_pool)
  temp.test <- defaultSummary(data.frame(obs = fold.test$dietaryMCPD, pred = testpred))
  result.test[i, ] <- c(temp.test["RMSE"], temp.test["Rsquared"], temp.test["MAE"])
}

# 计算并打印平均性能指标
mean_train_R2 <- mean(result.train$R2)
mean_test_R2 <- mean(result.test$R2)

R2_CAT <- result.test$R2
RMSE_CAT <- result.test$RMSE
MAE_CAT <- result.test$MAE

# 初始化并填充结果数据框
Result_total <- data.frame(
  Model = character(8),  # 假设前面有七个模型，第八个是CatBoost
  Train_RMSE = numeric(8),
  Train_R2 = numeric(8),
  Train_MAE = numeric(8),
  Test_RMSE = numeric(8),
  Test_R2 = numeric(8),
  Test_MAE = numeric(8),
  stringsAsFactors = FALSE
)

# 存储CatBoost模型的结果
Result_total[8, ] <- c(
  'CAT',
  mean(result.train$RMSE),
  mean(result.train$R2),
  mean(result.train$MAE),
  mean(result.test$RMSE),
  mean(result.test$R2),
  mean(result.test$MAE)
)


```

# 03.Output final results
